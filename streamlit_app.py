import streamlit as st
import pydeck as pdk
import altair as alt
import numpy as np
import pandas as pd
import os
import requests
from bs4 import BeautifulSoup
import re

# Hide the deploy menu
# https://discuss.streamlit.io/t/hide-deploy-and-streamlit-mainmenu/52433
st.set_page_config(page_title="KMindä¸­è‹±è¯å…¸")
st.markdown("""
    <style>
        .reportview-container {
            margin-top: -2em;
        }
        #MainMenu {visibility: hidden;}
        .stDeployButton {display:none;}
        header {display: hidden;}
        footer {visibility: hidden;}
        #stDecoration {display:none;}
    </style>
""", unsafe_allow_html=True)

dict_tag_mapping = {
    "gre": "GRE",
    "toefl": "æ‰˜ç¦",
    "cet6": "å…­çº§",
    "ielts": "é›…æ€",
    "ky": "è€ƒç ”",
    "cet4": "å››çº§",
    "gk": "é«˜è€ƒ",
    "zk": "ä¸­è€ƒ"
}

dict_exchange_mapping = {
    "p:": "è¿‡å»å¼ï¼š",
    "d:": "è¿‡å»åˆ†è¯ï¼š",
    "i:": "ç°åœ¨åˆ†è¯ï¼š",
    "3:": "ç¬¬ä¸‰äººç§°å•æ•°ï¼š",
    "r:": "æ¯”è¾ƒçº§ï¼š",
    "t:": "æœ€é«˜çº§ï¼š",
    "s:": "åè¯å¤æ•°å½¢å¼ï¼š"
}

# ä»Bingæœç´¢å›¾ç‰‡
def fetch_thumbnail_url(query):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    search_url = f'https://www.bing.com/images/search?q={query}'
    response = requests.get(search_url, headers=headers)
    
    if response.status_code != 200:
        print("Failed to fetch search results")
        return None

    soup = BeautifulSoup(response.text, 'html.parser')
    image_element = soup.find('img', class_='mimg')
    
    if image_element and image_element.has_attr('src'):
        return image_element['src']
    
    # Try to find the image URL in the data-murl attribute if src is not available
    image_element = soup.find('a', class_='iusc')
    if image_element and 'm' in image_element.attrs:
        m_url = image_element['m']
        match = re.search(r'"murl":"(.*?)"', m_url)
        if match:
            return match.group(1)
    
    return None

# ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä¸­æ–‡å­—ç¬¦
def contains_chinese(text):
    return bool(re.search(r'[\u4e00-\u9fff]', text))

def search_prefix(df, word):
    return df[df['word'].str.startswith(word, na=False)]

def search_suffix(df, word):
    return df[df['word'].str.endswith(word, na=False)]

def search_contain(df, word):
    return df[df['word'].str.contains(word, na=False)]

def search_match(df, word):
    return df[df['word'].str.lower() == word.lower()]

# LOAD DATA ONCE
@st.cache_resource
def load_data():
    path = "./data/kdict.csv"
    data = pd.read_csv(path)
    return data

data = load_data()

st.title("KMindä¸­è‹±è¯å…¸")
st.subheader(":rainbow[è¶…çº§è”æƒ³æ€ç»´è‹±è¯­å­¦ä¹ ]")
st.write("è§£é”å•è¯å­¦ä¹ çš„ç»ˆæå·¥å…·ï¼KMindä¸­è‹±è¯å…¸é€šè¿‡è¯æ±‡çš„è”æƒ³å…³è”ï¼Œæ„å»ºåŒå‰ç¼€/åç¼€/å…³é”®è¯å•è¯ä¹‹å‰çš„æ–°æ¡¥æ¢ï¼Œè®©å­¦ä¹ è‹±è¯­æ›´åŠ æœ‰è¶£ã€‚æå‡è¯æ±‡é‡ï¼Œä»æœªå¦‚æ­¤è½»æ¾æœ‰è¶£ã€‚")
st.caption("å¯ä»¥ä½¿ç”¨\"-\"ç¬¦å·æ¥æŸ¥è¯¢å‰ç¼€ä¸åç¼€ï¼Œä¾‹å¦‚ï¼š-tionå¯ä»¥æŸ¥è¯¢tionç»“å°¾çš„å•è¯ï¼Œlike-å¯ä»¥æŸ¥è¯¢likeå¼€å¤´çš„å•è¯ã€‚")
st.divider()

text_input = st.text_input("Hi, è¯·åœ¨è¿™é‡Œè¾“å…¥ä¸­è‹±æ–‡å•è¯ ğŸ’â€â™‚ï¸", "play")

if text_input:

    if contains_chinese(text_input):
        df = data[data['translation'].str.contains(text_input, na=False)]
    elif '-' not in text_input:
        df = search_contain(data, text_input)

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸text_inputå®Œå…¨åŒ¹é…çš„å•è¯ï¼Œå¦‚æœæœ‰ï¼Œåˆ™ç§»åŠ¨åˆ°é¦–è¡Œ
        if (df['word'] == text_input).any():
            matching_rows = df[df['word'] == text_input]
            non_matching_rows = df[df['word'] != text_input]
            df = pd.concat([matching_rows, non_matching_rows], ignore_index=True)
    else:
        if text_input.startswith("-"):
            df = search_suffix(data, text_input[1:])
        elif text_input.endswith("-"):
            df = search_prefix(data, text_input[:-1])

    # å¦‚æœç»“æœå¤ªå¤šï¼Œåˆ™åªå±•ç¤ºå‰10ä¸ªå•è¯
    num = len(df)
    msg = f"å…±æ‰¾åˆ° {num} ä¸ªç›¸å…³å•è¯"
    if len(df) > 10:
        msg += "ï¼Œä»¥ä¸‹ä¸ºå‰10ä¸ªå•è¯ï¼š"
    st.caption(msg)
    df = df.head(10)

    for _, row in df.iterrows():

        word = row['word']
        st.subheader(word)
        image_url = fetch_thumbnail_url(word)
        if image_url is not None:
            st.image(image_url)
        st.caption(f"- å‘éŸ³ï¼š[{row['phonetic']}]")
        st.caption(f"- ä¸­è¯‘ï¼š{row['translation'].replace('\\n', '; ')}")
        st.caption(f"- è‹±è¯‘ï¼š{row['definition'].replace('\\n', '; ')}")

        translated_tags = '/'.join(dict_tag_mapping.get(tag, tag) for tag in row['tag'].split())
        st.caption(f"- è€ƒçº²ï¼š{translated_tags}")

        if not pd.isna(row['exchange']):
            exchange_str = row['exchange']
            for key, value in dict_exchange_mapping.items():
                exchange_str = exchange_str.replace(key, value)
            st.caption(f"- {'; '.join(exchange_str.split('/'))}")

        st.divider()


st.caption(":email: 173163933@qq.com ***(Wang Kang)***")